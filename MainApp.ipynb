{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Crunza17/Colab.ChatBot/blob/main/MainApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL_3966_0TOm",
        "outputId": "b71a3773-4b90-44e3-9d35-f21ab07d6f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Ruta de la base de datos vectorial: /content/drive/MyDrive/Proyecto/vector_store\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/Proyecto\"\n",
        "VECTOR_STORE_DIR = f\"{PROJECT_ROOT}/vector_store\"\n",
        "\n",
        "print(f\"Ruta de la base de datos vectorial: {VECTOR_STORE_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nIfGCQRn0tZA"
      },
      "outputs": [],
      "source": [
        "## Desinstalamos todo para empezar desde un estado completamente limpio.\n",
        "\n",
        "# Instalamos versiones exactas y recientes que sabemos que funcionan juntas.\n",
        "!pip install langchain langchain-core langchain-community\n",
        "!pip install langchain-google-genai\n",
        "!pip install sentence-transformers\n",
        "!pip install pypdf\n",
        "!pip install -U gradio\n",
        "!pip install protobuf==3.20.3\n",
        "!pip install chromadb==0.4.22\n",
        "!pip install pysqlite3-binary==0.5.2\n",
        "\n",
        "print(\"\\n‚úÖ ¬°Instalaci√≥n completada! Por favor, REINICIA LA SESI√ìN para que los cambios surtan efecto.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu8l8Ueo0wEF",
        "outputId": "bc7750d1-3e91-4c08-c123-fa634090a132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key de Google configurada correctamente.\n"
          ]
        }
      ],
      "source": [
        "# API Key guardada en Google Secrets\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "try:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"‚úÖ API Key de Google configurada correctamente.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Error: No se pudo encontrar la API Key. Aseg√∫rate de haberla guardado en los 'Secretos' con el nombre GOOGLE_API_KEY.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "UbPybgI6080e",
        "outputId": "bc89526d-e215-4d5a-c71e-94b5e583b149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Inicializando el chatbot con la nueva arquitectura LCEL...\n",
            "   - Cargando modelo de embeddings (Hugging Face)...\n",
            "   - Cargando base de datos vectorial desde '/content/drive/MyDrive/Proyecto/vector_store'...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "`np.float_` was removed in the NumPy 2.0 release. Use `np.float64` instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2812425912.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Creamos la instancia del chatbot (esta l√≠nea no cambia)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mchatbot_instance_rag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatbotRAG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_store_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVECTOR_STORE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2812425912.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vector_store_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   - Cargando base de datos vectorial desde '{vector_store_path}'...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         self.vector_store = Chroma(\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mpersist_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvector_store_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0membedding_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/chroma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;34m\"\"\"Initialize with a Chroma client.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mClientCreator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdminClient\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAdminClientCreator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenTransportHeader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDEFAULT_DATABASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_TENANT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCollection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m from chromadb.api.types import (\n\u001b[1;32m      9\u001b[0m     \u001b[0mCollectionMetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/api/models/Collection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0muuid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUUID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_functions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m from chromadb.api.types import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/utils/embedding_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtenacity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstop_after_attempt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_if_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from chromadb.api.types import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mDocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mDocuments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/chromadb/api/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m# Images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mImageDType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImageDType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mImages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__expired_attributes__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    398\u001b[0m                 \u001b[0;34mf\"`np.{attr}` was removed in the NumPy 2.0 release. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0;34mf\"{__expired_attributes__[attr]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: `np.float_` was removed in the NumPy 2.0 release. Use `np.float64` instead."
          ]
        }
      ],
      "source": [
        "# Importamos todas las herramientas necesarias de LangChain y Gradio\n",
        "import gradio as gr\n",
        "import time\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "class ChatbotRAG:\n",
        "    # NUEVO M√âTODO para formatear los documentos en un solo string\n",
        "    def format_docs(self, docs):\n",
        "        \"\"\"Combina el page_content de varios documentos en un solo string.\"\"\"\n",
        "        return \"\\n\\n---\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    def __init__(self, vector_store_path):\n",
        "        print(\"‚è≥ Inicializando el chatbot con la nueva arquitectura LCEL...\")\n",
        "\n",
        "        print(\"   - Cargando modelo de embeddings (Hugging Face)...\")\n",
        "        model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        self.embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "\n",
        "        print(f\"   - Cargando base de datos vectorial desde '{vector_store_path}'...\")\n",
        "        self.vector_store = Chroma(\n",
        "            persist_directory=vector_store_path,\n",
        "            embedding_function=self.embeddings,\n",
        "            collection_name=\"documentos_quimica\"\n",
        "        )\n",
        "\n",
        "        retriever = self.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "        print(\"   - Configurando el modelo de lenguaje de Google (Gemini)...\")\n",
        "        self.llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-pro-latest\", # Usando el nombre del modelo m√°s reciente y estable\n",
        "            temperature=0.3,\n",
        "            convert_system_message_to_human=True\n",
        "        )\n",
        "\n",
        "        prompt_template = \"\"\"\n",
        "        Eres un asistente amigable y servicial para estudiantes y maestros. Tu tarea es responder a las preguntas de los usuarios bas√°ndote √∫nicamente en el contexto proporcionado.\n",
        "        **Responde siempre en espa√±ol, sin importar el idioma del contexto.** Si la respuesta no se encuentra en el contexto, di amablemente \"Lo siento, no tengo informaci√≥n sobre eso en mis documentos.\"\n",
        "\n",
        "        CONTEXTO:\n",
        "        {context}\n",
        "\n",
        "        PREGUNTA:\n",
        "        {question}\n",
        "\n",
        "        Respuesta √∫til:\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "        print(\"   - Creando la cadena de RAG con LCEL...\")\n",
        "        self.rag_chain = (\n",
        "            # --- ¬°AQU√ç EST√Å LA MODIFICACI√ìN CLAVE! ---\n",
        "            # Ahora, el contexto se crea pasando la salida del retriever\n",
        "            # a trav√©s de nuestra nueva funci√≥n de formato.\n",
        "            {\"context\": retriever | self.format_docs, \"question\": RunnablePassthrough()}\n",
        "            | prompt\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "        print(\"\\n‚úÖ ¬°Chatbot RAG (LCEL) listo para funcionar!\")\n",
        "\n",
        "    def get_response(self, question):\n",
        "        \"\"\"Obtiene una respuesta del chatbot usando la nueva cadena LCEL.\"\"\"\n",
        "        try:\n",
        "            result = self.rag_chain.invoke(question)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Error durante la invocaci√≥n de la cadena: {e}\")\n",
        "            return \"Lo siento, ha ocurrido un error al procesar tu pregunta.\"\n",
        "\n",
        "# Creamos la instancia del chatbot (esta l√≠nea no cambia)\n",
        "chatbot_instance_rag = ChatbotRAG(vector_store_path=VECTOR_STORE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda de prueba en MainApp.ipynb\n",
        "\n",
        "print(\"üî¨ Realizando una prueba COMPLETA de la cadena RAG...\")\n",
        "test_question = \"¬øQue es molaridad?\"\n",
        "\n",
        "try:\n",
        "    # Invocamos la cadena completa, exactamente como lo har√≠a Gradio.\n",
        "    final_response = chatbot_instance_rag.get_response(test_question)\n",
        "\n",
        "    print(\"\\n‚úÖ ¬°La cadena RAG se ejecut√≥ exitosamente!\")\n",
        "    print(\"\\nRespuesta generada por el LLM:\")\n",
        "    print(\"--------------------------------\")\n",
        "    print(final_response)\n",
        "    print(\"--------------------------------\")\n",
        "\n",
        "    if \"no tengo informaci√≥n\" in final_response.lower():\n",
        "         print(\"\\n‚ö†Ô∏è ADVERTENCIA: La cadena funcion√≥, pero el LLM no encontr√≥ la respuesta en el contexto. Revisa el paso de formateo.\")\n",
        "    else:\n",
        "        print(\"\\nüéâ ¬°√âxito total! La cadena est√° devolviendo contexto relevante.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Ocurri√≥ un error al invocar la cadena RAG: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "ewOAhbTj8Bwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HU6ApvSP1q_W"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat_function_with_history(message, history):\n",
        "    respuesta_bot = chatbot_instance_rag.get_response(message)\n",
        "\n",
        "    for i in range(len(respuesta_bot)):\n",
        "        time.sleep(0.02)\n",
        "        yield respuesta_bot[: i+1]\n",
        "\n",
        "chat_interface = gr.ChatInterface(\n",
        "    fn=chat_function_with_history,\n",
        "    title=\"ü§ñ Asistente Virtual de Qu√≠mica\",\n",
        "    description=\"Chatea conmigo sobre la carrera. Recuerdo nuestra conversaci√≥n.\",\n",
        "    examples=[ee\n",
        "        \"¬øQu√© materias se ven en primer semestre?\",\n",
        "        \"¬øQue es molaridad?\"\n",
        "    ],\n",
        "\n",
        "    chatbot=gr.Chatbot(\n",
        "        avatar_images=(None, \"https://i.imgur.com/2KmzC5E.png\"),\n",
        "        type=\"messages\"\n",
        "    ),\n",
        "\n",
        "    theme=gr.themes.Soft(primary_hue=\"blue\"),\n",
        ")\n",
        "\n",
        "print(\"üöÄ Lanzando la interfaz de Gradio...\")\n",
        "chat_interface.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}